{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CycleGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bethanystate/CS7641_project/blob/master/CycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EF3AUvyajLX",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WEFn3h5JwyL",
        "colab_type": "text"
      },
      "source": [
        "## Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev7jcnyIsJDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/cycleGAN\")\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGZs_x5RJ2JU",
        "colab_type": "text"
      },
      "source": [
        "## Import Tensorflow and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbKpZn1cadYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_addons as tfa\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "tfds.disable_progress_bar()\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BVYBSVaJz14",
        "colab_type": "text"
      },
      "source": [
        "## GPU Info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZPC2PGWZ4yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "  device_name = tf.test.gpu_device_name()\n",
        "  print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjesMeCZbL8Y",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRrD3nQmbg5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 1 \n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "LAMBDA = 10\n",
        "LEARNING_RATE = 2e-4\n",
        "BETA_1 = 0.5\n",
        "EPOCHS = 200\n",
        "DECAY_EPOCHS = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd5tH0_Nbse0",
        "colab_type": "text"
      },
      "source": [
        "# Input Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjuEUiuagjQ8",
        "colab_type": "text"
      },
      "source": [
        "## Load a dataset\n",
        "\n",
        "The easiest way of loading a dataset is tfds.load. It will:\n",
        "\n",
        "1. Download the data and save it as tfrecord files.\n",
        "2. Load the tfrecord and create the tf.data.Dataset\n",
        "\n",
        "train_X: Paintings\n",
        "\n",
        "train_Y: Landscape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H0rO1Iobt23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Monet\n",
        "dataset, metadata = tfds.load('cycle_gan/monet2photo', with_info=True, as_supervised=True)\n",
        "\n",
        "# cezanne\n",
        "# dataset, metadata = tfds.load('cycle_gan/cezanne2photo', with_info=True, as_supervised=True) \n",
        "\n",
        "# ukiyoe\n",
        "# dataset, metadata = tfds.load('cycle_gan/ukiyoe2photo', with_info=True, as_supervised=True) \n",
        "\n",
        "# vangogh\n",
        "# dataset, metadata = tfds.load('cycle_gan/vangogh2photo', with_info=True, as_supervised=True) \n",
        "\n",
        "train_X, train_Y = dataset['trainA'], dataset['trainB']\n",
        "test_X, test_Y = dataset['testA'], dataset['testB']\n",
        "\n",
        "print(metadata)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K10bC-j0dHEZ",
        "colab_type": "text"
      },
      "source": [
        "## Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXRWjUYdcXMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_crop(image):\n",
        "  cropped_image = tf.image.random_crop(image, size=[IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "  \n",
        "  return cropped_image\n",
        "\n",
        "# Normalize the images to [-1, 1]\n",
        "def normalize(image):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = (image / 127.5) - 1\n",
        "\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlbLaWm9cxlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_jitter(image):\n",
        "  # Resizing to 286 x 286 x 3\n",
        "  image = tf.image.resize(image, [286, 286], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "  # randomly cropping to 256 x 256 x 3\n",
        "  image = random_crop(image)\n",
        "\n",
        "  # random mirroring \n",
        "  image = tf.image.random_flip_left_right(image)\n",
        "\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEyyhThWdIEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_image_train(image, label):\n",
        "  image = random_jitter(image)\n",
        "  image = normalize(image)\n",
        "  return image\n",
        "\n",
        "def preprocess_image_test(image, label):\n",
        "  image = normalize(image)\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERZFqyFxf3Hk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create training dataset\n",
        "train_X = train_X.map(preprocess_image_train, num_parallel_calls=AUTOTUNE).cache()\n",
        "train_Y = train_Y.map(preprocess_image_train, num_parallel_calls=AUTOTUNE).cache()\n",
        "\n",
        "train_dataset = tf.data.Dataset.zip((train_X, train_Y)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9Nlx09agS8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create testing dataset\n",
        "test_X = test_X.map(preprocess_image_test, num_parallel_calls=AUTOTUNE).cache()\n",
        "test_Y = test_Y.map(preprocess_image_test, num_parallel_calls=AUTOTUNE).cache()\n",
        "\n",
        "test_dataset = tf.data.Dataset.zip((test_X, test_Y)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ENK0y8AdjXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_batches = len(list(train_dataset.as_numpy_iterator()))\n",
        "print('Batch size: {}, Total batches per epoch: {}'.format(BATCH_SIZE, total_batches))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4iSuG8uEKy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgX = plt.imread(\"painting.jpeg\")\n",
        "imgX = preprocess_image_train(imgX, 0)\n",
        "imgX = imgX[tf.newaxis, :]\n",
        "\n",
        "imgY = plt.imread(\"landscape.jpg\")\n",
        "imgY = preprocess_image_train(imgY, 0)\n",
        "imgY = imgY[tf.newaxis, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_SCSx2jbuM0",
        "colab_type": "text"
      },
      "source": [
        "## Visualize Random Jittering\n",
        "\n",
        "1. Resize an image to bigger height and width\n",
        "2. Randomly crop to the target size\n",
        "3. Randomly flip image horizonatally "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuknCm3eiSuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.subplot(121)\n",
        "plt.title('Input Image')\n",
        "plt.imshow(imgX[0]*0.5 + 0.5)\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title('Input Image with random jittering')\n",
        "plt.imshow(random_jitter(imgX[0]) * 0.5 + 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tnP3v3Cipbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.subplot(121)\n",
        "plt.title('Input Image')\n",
        "plt.imshow(imgY[0]*0.5 + 0.5)\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title('Input Image with random jittering')\n",
        "plt.imshow(random_jitter(imgY[0]) * 0.5 + 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJP13Ofjl-yV",
        "colab_type": "text"
      },
      "source": [
        "# Build the Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf9EWISUbaLN",
        "colab_type": "text"
      },
      "source": [
        "## ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6XEEZ_e1Lqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Padding2D(tf.keras.layers.Layer):\n",
        "  def __init__(self, padding, padding_type, **kwargs):\n",
        "    super(Padding2D, self).__init__(**kwargs)\n",
        "    self.padding = [[0, 0], [padding, padding], [padding, padding], [0, 0]]\n",
        "    self.padding_type = padding_type\n",
        "\n",
        "  def call(self, inputs, **kwargs):\n",
        "    if self.padding_type == \"reflect\":\n",
        "      return tf.pad(inputs, self.padding, mode='REFLECT')\n",
        "\n",
        "    elif self.padding_type == \"zero\":\n",
        "      return tf.pad(inputs, self.padding, mode='CONSTANT')\n",
        "\n",
        "    elif self.padding_type == \"symmetric\":\n",
        "      return tf.pad(inputs, self.padding, mode='SYMMETRIC')\n",
        "    else:\n",
        "      raise NotImplementedError('padding [%s] is not implemented' % self.padding_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PA_BW4VlDVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv(filters, kernel_size, strides=1, padding=\"same\", name=\"\", norm_type=\"InstanceNorm\", use_bias=True):\n",
        "\t# Weights initializer\n",
        "\tinit = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "\tg = tf.keras.Sequential(name=name)\n",
        " \n",
        "\tg.add(tf.keras.layers.Conv2D(filters, kernel_size, strides, padding=padding, kernel_initializer=init, use_bias=use_bias))\n",
        "\t\n",
        "\tif norm_type.lower()==\"batchnorm\":\n",
        "\t\tg.add(tf.keras.layers.BatchNormalization())\n",
        "\telif norm_type.lower()==\"instancenorm\":\n",
        "\t\tg.add(tfa.layers.InstanceNormalization(axis=-1)) \n",
        "\t\n",
        "\tg.add(tf.keras.layers.Activation('relu'))\n",
        " \n",
        "\treturn g\n",
        "\n",
        "def convTranspose(filters, kernel_size, strides=1, padding=\"same\", name=\"\", norm_type=\"instanceNorm\", use_bias=True):\n",
        "\t# Weights initializer\n",
        "\tinit = tf.random_normal_initializer(0, 0.02)\n",
        "\n",
        "\tg = tf.keras.Sequential(name=name)\n",
        "\tg.add(tf.keras.layers.Conv2DTranspose(filters, kernel_size, strides, padding=padding, kernel_initializer=init, use_bias=use_bias))\n",
        "\n",
        "\tif norm_type.lower()==\"batchnorm\":\n",
        "\t\tg.add(tf.keras.layers.BatchNormalization())\n",
        "\telif norm_type.lower()==\"instancenorm\":\n",
        "\t\tg.add(tfa.layers.InstanceNormalization(axis=-1)) \n",
        "\t\n",
        "\tg.add(tf.keras.layers.Activation('relu'))\n",
        " \n",
        "\treturn g"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJKjfmkynys3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generator a resnet block\n",
        "def resnet_block(n_filters, input_layer, use_dropout, name=\"\", padding_type=\"reflect\", norm_type=\"InstanceNorm\", type_net=\"resnet\", use_bias=True):\n",
        "\t\"\"\"\n",
        "\tInitialize the Resnet block\n",
        "\n",
        "\tA resnet block is a conv black with skip connections.\n",
        "\tOriginal renet paper: https://arxiv.org/pdf/1512.03385.pdf\n",
        "\t\"\"\"\n",
        "\t# Weight initialization\n",
        "\tinitializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "\t\n",
        "\tg = tf.keras.Sequential(name=name)\n",
        " \n",
        "\tg.add(Padding2D(1, padding_type=padding_type))\n",
        "\tg.add(tf.keras.layers.Conv2D(filters=n_filters, kernel_size=3, padding=\"valid\", kernel_initializer=initializer, use_bias=use_bias))\n",
        " \n",
        "\tif norm_type.lower()==\"batchborm\":\n",
        "\t\tg.add(tf.keras.layers.BatchNormalization())\n",
        "\telif norm_type.lower()==\"instancenorm\":\n",
        "\t\tg.add(tfa.layers.InstanceNormalization(axis=-1))\n",
        "\telse:\n",
        "\t\traise NotImplementedError('Norm Type [%s] is invalid' % norm_type)\n",
        "\n",
        "\tg.add(tf.keras.layers.Activation('relu'))\n",
        " \n",
        "\tif use_dropout:\n",
        "\t\tg.add(tf.keras.layers.Dropout(0.5))\n",
        " \n",
        "\tg.add(Padding2D(1, padding_type=padding_type))\n",
        "\tg.add(tf.keras.layers.Conv2D(filters=n_filters, kernel_size=3, padding=\"valid\", kernel_initializer=initializer, use_bias=use_bias))\n",
        "\n",
        "\tif norm_type.lower()==\"batchborm\":\n",
        "\t\tg.add(tf.keras.layers.BatchNormalization())\n",
        "\telif norm_type.lower()==\"instancenorm\":\n",
        "\t\tg.add(tfa.layers.InstanceNormalization(axis=-1))\n",
        "\telse:\n",
        "\t\traise NotImplementedError('Norm Type [%s] is invalid' % norm_type)\n",
        "\n",
        "\tif type_net==\"resnet\":\n",
        "\t\tg = tf.keras.layers.add([g(input_layer), input_layer])\n",
        "\t\treturn g\n",
        "\telse:\n",
        "\t\tg.add(tf.keras.layers.Activation('relu'))\n",
        "\t\treturn g(input_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nScorcjlWVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the standalone generator model\n",
        "def resnet_generator(\n",
        "\t\timage_shape=(256, 256, 3), \n",
        "\t\tnorm_type=\"InstanceNorm\", \n",
        "\t\tuse_dropout=False,\n",
        "\t\tn_resnet=9, \n",
        "\t\ttype_net=\"resnet\", \n",
        "\t\tpadding_type=\"reflect\"\n",
        "\t\t):\n",
        "\n",
        "\t\"\"\"\n",
        "\tConstruct a Resnet_based generator\n",
        "\n",
        "\tArgs:\n",
        "\t\tnorm_type \t\t\t\t\t-- nomralization layer: Batch Normalization | Instance Normalization\n",
        "\t\tuse_dropout (bool)\t-- if use dropout layers\n",
        "\t\tn_resnet (int)\t\t\t-- the number of ResNet blocks\n",
        "\t\ttype_net (str)\t\t\t-- Residual | Non-Residual\n",
        "\t\tpadding_type (str)\t-- the name of padding layer in conv layers: reflect | zero | symmetric\n",
        "\t\"\"\"\n",
        "\n",
        "\tassert(n_resnet >= 0)\n",
        "\t\n",
        "\tif norm_type.lower()==\"batchnorm\":\n",
        "\t\tuse_bias=False\n",
        "\telif norm_type.lower()==\"instancenorm\":\n",
        "\t\tuse_bias=True\n",
        "\telse:\n",
        "\t\traise NotImplementedError('Norm Type [%s] is invalid' % norm_type)\n",
        " \n",
        "\t# Image Input\n",
        "\tinputs = tf.keras.Input(shape=image_shape, name=\"Image\")\n",
        " \n",
        "\t# Spatial Padding\n",
        "\tg = Padding2D(padding=3, padding_type=padding_type, name=\"Padding\")(inputs)\n",
        " \n",
        "\t# c7s1-64\n",
        "\tg = conv(filters=64, kernel_size=7, strides=1, padding=\"valid\", norm_type=norm_type, name=\"c7s1-64\")(g)\n",
        " \n",
        "\t# d128\n",
        "\tg = conv(filters=128, kernel_size=3, strides=2, padding=\"same\", norm_type=norm_type, name=\"d128\")(g)\n",
        " \n",
        "\t# d256\n",
        "\tg = conv(filters=256, kernel_size=3, strides=2, padding=\"same\", norm_type=norm_type, name=\"d256\")(g)\n",
        "\n",
        "\t# R256\n",
        "\tfor n in range(n_resnet):\n",
        "\t\tg = resnet_block(n_filters=256, input_layer=g, use_dropout=use_dropout, name=\"R256_\"+str(n+1), \n",
        "\t\t\t\t\t\t\t\t\t\tpadding_type=padding_type, norm_type=norm_type, type_net=type_net)\n",
        "\t\n",
        "\t# u128\n",
        "\tg = convTranspose(filters=128, kernel_size=3, strides=2, padding=\"same\", name=\"u128\", norm_type=norm_type)(g)\n",
        " \n",
        "\t# u64\n",
        "\tg = convTranspose(filters=64, kernel_size=3, strides=2, padding=\"same\", name=\"u64\", norm_type=norm_type)(g)\n",
        "\n",
        "\tg = Padding2D(3, padding_type=padding_type)(g)\n",
        " \n",
        "\t# c7s1-3\n",
        "\toutputs = tf.keras.layers.Conv2D(filters=3, kernel_size=7, strides=1, padding=\"valid\", name=\"c7s1-3\", activation='tanh')(g)\n",
        " \n",
        "\t# define model\n",
        "\tmodel = tf.keras.Model(inputs=inputs, outputs=outputs, name=type_net+\"_Generator\")\n",
        " \n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tvp4gXAcnMCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the model\n",
        "model = resnet_generator(\n",
        "    image_shape=(256, 256, 3), \n",
        "\t\tnorm_type=\"InstanceNorm\", \n",
        "\t\tuse_dropout=False,\n",
        "\t\tn_resnet=9, \n",
        "\t\ttype_net=\"nonresnet\", \n",
        "\t\tpadding_type=\"reflect\"\n",
        "\t\t)\n",
        "\n",
        "# summarize the model\n",
        "model.summary()\n",
        "\n",
        "# plot the model\n",
        "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, dpi=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZZ3pclxbrh_",
        "colab_type": "text"
      },
      "source": [
        "## U-Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC69i1IxAJtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def downsample(filters, size, norm_type='batchnorm', apply_norm=True, use_bias=True):\n",
        "  \"\"\"Downsamples an input.\n",
        "  Conv2D => Batchnorm => LeakyRelu\n",
        "  Args:\n",
        "    filters: number of filters\n",
        "    size: filter size\n",
        "    norm_type: Normalization type; either 'batchnorm' or 'instancenorm'.\n",
        "    apply_norm: If True, adds the batchnorm layer\n",
        "  Returns:\n",
        "    Downsample Sequential Model\n",
        "  \"\"\"\n",
        "  initializer = tf.keras.initializers.RandomNormal(0., 0.02)\n",
        "\n",
        "  result = tf.keras.Sequential()\n",
        "  result.add(\n",
        "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
        "                             kernel_initializer=initializer, use_bias=use_bias))\n",
        "\n",
        "  if apply_norm:\n",
        "    if norm_type.lower() == 'batchnorm':\n",
        "      result.add(tf.keras.layers.BatchNormalization())\n",
        "    elif norm_type.lower() == 'instancenorm':\n",
        "      result.add(tfa.layers.InstanceNormalization(axis=-1))\n",
        "\n",
        "  result.add(tf.keras.layers.LeakyReLU(0.2))\n",
        "\n",
        "  return result\n",
        "\n",
        "\n",
        "def upsample(filters, size, norm_type='batchnorm', apply_dropout=False, use_bias=True):\n",
        "  \"\"\"Upsamples an input.\n",
        "  Conv2DTranspose => Batchnorm => Dropout => Relu\n",
        "  Args:\n",
        "    filters: number of filters\n",
        "    size: filter size\n",
        "    norm_type: Normalization type; either 'batchnorm' or 'instancenorm'.\n",
        "    apply_dropout: If True, adds the dropout layer\n",
        "  Returns:\n",
        "    Upsample Sequential Model\n",
        "  \"\"\"\n",
        "\n",
        "  initializer = tf.keras.initializers.RandomNormal(0., 0.02)\n",
        "\n",
        "  result = tf.keras.Sequential()\n",
        "  result.add(\n",
        "      tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
        "                                      padding='same',\n",
        "                                      kernel_initializer=initializer,\n",
        "                                      use_bias=use_bias))\n",
        "\n",
        "  if norm_type.lower() == 'batchnorm':\n",
        "    result.add(tf.keras.layers.BatchNormalization())\n",
        "  elif norm_type.lower() == 'instancenorm':\n",
        "    result.add(tfa.layers.InstanceNormalization(axis=-1))\n",
        "\n",
        "  if apply_dropout:\n",
        "    result.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "  result.add(tf.keras.layers.ReLU(0.2))\n",
        "\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMslaTxjkNG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unet_generator(output_channels, norm_type='batchnorm'):\n",
        "  \"\"\"Modified u-net generator model (https://arxiv.org/abs/1611.07004).\n",
        "  Args:\n",
        "    output_channels: Output channels\n",
        "    norm_type: Type of normalization. Either 'batchnorm' or 'instancenorm'.\n",
        "  Returns:\n",
        "    Generator model\n",
        "  \"\"\"\n",
        "\n",
        "  assert(output_channels > 0)\n",
        "\n",
        "  if norm_type.lower()==\"batchnorm\":\n",
        "\n",
        "    use_bias = False\n",
        "  elif norm_type.lower()==\"instancenorm\":\n",
        "    use_bias = True\n",
        "  else:\n",
        "    raise NotImplementedError('Norm Type [%s] is invalid' % norm_type)\n",
        "\n",
        "  inputs = tf.keras.layers.Input(shape=[256,256,3])\n",
        "\n",
        "  down_stack = [\n",
        "      downsample(64, 4, norm_type, apply_norm=False, use_bias=use_bias),  # (bs, 128, 128, 64)\n",
        "      downsample(128, 4, norm_type, use_bias),  # (bs, 64, 64, 128)\n",
        "      downsample(256, 4, norm_type, use_bias),  # (bs, 32, 32, 256)\n",
        "      downsample(512, 4, norm_type, use_bias),  # (bs, 16, 16, 512)\n",
        "      downsample(512, 4, norm_type, use_bias),  # (bs, 8, 8, 512)\n",
        "      downsample(512, 4, norm_type, use_bias),  # (bs, 4, 4, 512)\n",
        "      downsample(512, 4, norm_type, use_bias),  # (bs, 2, 2, 512)\n",
        "      downsample(512, 4, norm_type, use_bias),  # (bs, 1, 1, 512)\n",
        "  ]\n",
        "\n",
        "  up_stack = [\n",
        "      upsample(512, 4, norm_type, apply_dropout=True, use_bias=use_bias),  # (bs, 2, 2, 1024)\n",
        "      upsample(512, 4, norm_type, apply_dropout=True, use_bias=use_bias),  # (bs, 4, 4, 1024)\n",
        "      upsample(512, 4, norm_type, apply_dropout=True, use_bias=use_bias),  # (bs, 8, 8, 1024)\n",
        "      upsample(512, 4, norm_type, use_bias),  # (bs, 16, 16, 1024)\n",
        "      upsample(256, 4, norm_type, use_bias),  # (bs, 32, 32, 512)\n",
        "      upsample(128, 4, norm_type, use_bias),  # (bs, 64, 64, 256)\n",
        "      upsample(64, 4, norm_type, use_bias),  # (bs, 128, 128, 128)\n",
        "  ]\n",
        "\n",
        "  last = tf.keras.layers.Conv2DTranspose(output_channels, 4, \n",
        "                                         strides=2,\n",
        "                                         padding='same', \n",
        "                                         kernel_initializer=tf.keras.initializers.RandomNormal(0., 0.02),\n",
        "                                         activation='tanh')  # (bs, 256, 256, 3)\n",
        "\n",
        "  x = inputs\n",
        "\n",
        "  # Downsampling through the model\n",
        "  skips = []\n",
        "  for down in down_stack:\n",
        "    x = down(x)\n",
        "    skips.append(x)\n",
        "\n",
        "  skips = reversed(skips[:-1])\n",
        "\n",
        "  # Upsampling and establishing the skip connections\n",
        "  for up, skip in zip(up_stack, skips):\n",
        "    x = up(x)\n",
        "    x = tf.keras.layers.Concatenate()([x, skip])\n",
        "\n",
        "  x = last(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcK_HlnlbwBw",
        "colab_type": "text"
      },
      "source": [
        "# Build the Discriminator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ipxTXsydgRg",
        "colab_type": "text"
      },
      "source": [
        "## PatchGAN\n",
        "\n",
        "1. Each block in the discriminator is (Conv -> Norm -> Leaky ReLU)\n",
        "2. The shape of the output after the last layer is (batch_size, 30, 30, 1)\n",
        "3. Each 30x30 patch of the output classifies a 70x70 portion of the input image\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rai2EScNm-Ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def downsampleD(filters, size, strides, name='', norm_type='batchnorm', apply_norm=True, use_bias=True):\n",
        "  \"\"\"Downsamples an input.\n",
        "  Conv2D => Batchnorm => LeakyRelu\n",
        "  Args:\n",
        "    filters: number of filters\n",
        "    size: filter size\n",
        "    norm_type: Normalization type; either 'batchnorm' or 'instancenorm'.\n",
        "    apply_norm: If True, adds the batchnorm layer\n",
        "  Returns:\n",
        "    Downsample Sequential Model\n",
        "  \"\"\"\n",
        "  initializer = tf.keras.initializers.RandomNormal(0., 0.02)\n",
        "\n",
        "  result = tf.keras.Sequential()\n",
        "  result.add(\n",
        "      tf.keras.layers.Conv2D(filters, size, strides=strides, padding='same',\n",
        "                             kernel_initializer=initializer, use_bias=use_bias, name=name))\n",
        "\n",
        "  if apply_norm:\n",
        "    if norm_type.lower() == 'batchnorm':\n",
        "      result.add(tf.keras.layers.BatchNormalization())\n",
        "    elif norm_type.lower() == 'instancenorm':\n",
        "      result.add(tfa.layers.InstanceNormalization(axis=-1))\n",
        "\n",
        "  result.add(tf.keras.layers.LeakyReLU(0.2))\n",
        "\n",
        "  return result\n",
        "\n",
        "\n",
        "def PatchDiscriminator(input_shape=(256, 256, 3), n_layers=3, norm_type='batchnorm'):\n",
        "  \"\"\"\n",
        "  PatchGan discriminator model (https://arxiv.org/abs/1611.07004).\n",
        "\n",
        "  Args:\n",
        "    norm_type:  --  Type of normalization. Either 'batchnorm' or 'instancenorm'.\n",
        "    n_layers:   --  Number of layers: 3 for PixelGAN | 5 for ImageGAN\n",
        "\n",
        "  Returns:\n",
        "    Discriminator model\n",
        "  \"\"\"\n",
        "\n",
        "  assert(n_layers >= 0)\n",
        "\n",
        "  if norm_type.lower()==\"batchnorm\":\n",
        "    use_bias = False\n",
        "  elif norm_type.lower()==\"instancenorm\":\n",
        "    use_bias = True\n",
        "  else:\n",
        "    raise NotImplementedError('Norm Type [%s] is invalid' % norm_type)\n",
        "\n",
        "  initializer = tf.keras.initializers.RandomNormal(0., 0.02)\n",
        "\n",
        "  inputs = tf.keras.layers.Input(shape=input_shape, name='Input')\n",
        "\n",
        "  d = downsampleD(filters=64, size=4, strides=2, norm_type=norm_type, apply_norm=False, use_bias=use_bias, name=\"C64\")(inputs) \n",
        "\n",
        "  for n in range(1, n_layers):\n",
        "    n_filters = 64*min(2**n, 8)\n",
        "    name = \"C\"+str(n_filters)+\"_\"+str(n)\n",
        "    d = downsampleD(filters=n_filters, size=4, strides=2, name=name, norm_type=norm_type, use_bias=use_bias)(d) \n",
        "\n",
        "  d = downsampleD(filters=64*min(2**n_layers, 8), size=4, strides=1, norm_type=norm_type, use_bias=use_bias, name=\"C512\")(d) \n",
        "\n",
        "  outputs = tf.keras.layers.Conv2D(filters=1, \n",
        "                                   kernel_size=4, \n",
        "                                   strides=1,\n",
        "                                   padding=\"same\",\n",
        "                                   kernel_initializer=initializer,\n",
        "                                   name=\"Output\")(d)  \n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=outputs, name=\"PatchGAN\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLnxaNnBmCM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator = PatchDiscriminator(n_layers=3, norm_type=\"instancenorm\")\n",
        "\n",
        "tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=70)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGOOk12TvGOw",
        "colab_type": "text"
      },
      "source": [
        "## PixelGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZLYnxJtvJvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode(filters, size, norm_type='batchnorm', apply_norm=True, use_bias=True):\n",
        "  \"\"\"Downsamples an input.\n",
        "  Conv2D => Batchnorm => LeakyRelu\n",
        "  Args:\n",
        "    filters: number of filters\n",
        "    size: filter size\n",
        "    norm_type: Normalization type; either 'batchnorm' or 'instancenorm'.\n",
        "    apply_norm: If True, adds the batchnorm layer\n",
        "  Returns:\n",
        "    Downsample Sequential Model\n",
        "  \"\"\"\n",
        "  initializer = tf.keras.initializers.RandomNormal(0., 0.02)\n",
        "\n",
        "  result = tf.keras.Sequential()\n",
        "  result.add(\n",
        "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='valid',\n",
        "                             kernel_initializer=initializer, use_bias=use_bias))\n",
        "\n",
        "  if apply_norm:\n",
        "    if norm_type.lower() == 'batchnorm':\n",
        "      result.add(tf.keras.layers.BatchNormalization())\n",
        "    elif norm_type.lower() == 'instancenorm':\n",
        "      result.add(tfa.layers.InstanceNormalization(axis=-1))\n",
        "\n",
        "  result.add(tf.keras.layers.LeakyReLU(0.2))\n",
        "\n",
        "  return result\n",
        "\n",
        "\n",
        "def PixelDiscriminator(input_shape=(256, 256, 3), norm_type='batchnorm'):\n",
        "  \"\"\"\n",
        "  Construct a 1x1 PatchGAN Descriminator (pixelGAN)\n",
        "\n",
        "  Args:\n",
        "    norm_type:  --  Type of normalization. Either 'batchnorm' or 'instancenorm'.\n",
        "\n",
        "  Returns:\n",
        "    Discriminator model\n",
        "  \"\"\"\n",
        "\n",
        "  if norm_type.lower()==\"batchnorm\":\n",
        "    use_bias = False\n",
        "  elif norm_type.lower()==\"instancenorm\":\n",
        "    use_bias = True\n",
        "  else:\n",
        "    raise NotImplementedError('Norm Type [%s] is invalid' % norm_type)\n",
        "\n",
        "  initializer = tf.keras.initializers.RandomNormal(0., 0.02)\n",
        "\n",
        "  inputs = tf.keras.layers.Input(shape=input_shape, name='input_image')\n",
        "\n",
        "  d = decode(64, 1, norm_type, apply_norm=False, use_bias=use_bias)(inputs) \n",
        "  d = decode(128, 1, norm_type, use_bias=use_bias)(d)\n",
        "\n",
        "  outputs = tf.keras.layers.Conv2D(filters=1, \n",
        "                                   kernel_size=1, \n",
        "                                   strides=1, \n",
        "                                   padding=\"valid\",\n",
        "                                   kernel_initializer=initializer,\n",
        "                                   use_bias=use_bias)(d) \n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTdBTXYTCGn0",
        "colab_type": "text"
      },
      "source": [
        "# CycleGAN Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKSE13PCG7p_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_G = resnet_generator()  # unet_generator(3, norm_type='instancenorm')\n",
        "generator_F = resnet_generator()  # unet_generator(3, norm_type='instancenorm')\n",
        "\n",
        "discriminator_X = PatchDiscriminator(norm_type=\"instancenorm\") # PixelDiscriminator | PatchDiscriminator(n_layer=5)\n",
        "discriminator_Y = PatchDiscriminator(norm_type=\"instancenorm\") # PixelDiscriminator | PatchDiscriminator(n_layer=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dC6QYk2Hj2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "G_Y = generator_G(imgX)\n",
        "F_X = generator_F(imgY)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "contrast = 8\n",
        "\n",
        "imgs = [imgX, G_Y, imgY, F_X]\n",
        "title = [\"Painting\", \"To Landscape\", \"Landscape\", \"To Painting\"]\n",
        "\n",
        "for i in range(len(imgs)):\n",
        "  plt.subplot(2, 2, i+1)\n",
        "  plt.title(title[i])\n",
        "  if i % 2 == 0:\n",
        "    plt.imshow(imgs[i][0] * 0.5 + 0.5)\n",
        "  else:\n",
        "    plt.imshow(imgs[i][0] * 0.5 * contrast + 0.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsPkeAL0NhYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.title(\"Is it a real landscape?\")\n",
        "plt.imshow(discriminator_Y(imgY)[0,...,-1], cmap=\"RdBu_r\")\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title(\"Is it a real painting?\")\n",
        "plt.imshow(discriminator_X(imgX)[0,...,-1], cmap=\"RdBu_r\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g7AaboOG4CN",
        "colab_type": "text"
      },
      "source": [
        "# Loss functions\n",
        "\n",
        "In CycleGAN, there is no paired data to train on, hence there is no guarantee that the input X and the target pair Y are meaningful during training. Thus in order to enforcee that network learns the correct mapping, the cycle consistency loss is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2CfSpQWO0P3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mse_loss = tf.keras.losses.MeanSquaredError()\n",
        "mae_loss = tf.keras.losses.MeanAbsoluteError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4yY_0ZNRBu2",
        "colab_type": "text"
      },
      "source": [
        "## Adversarial Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFj-dfuHO3iY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(real, generated):\n",
        "  real_loss = mse_loss(tf.ones_like(real), real)\n",
        "  generated_loss = mse_loss(tf.zeros_like(generated), generated)\n",
        "  total_discrimator_loss = real_loss + generated_loss\n",
        "\n",
        "  return total_discrimator_loss * 0.5\n",
        "\n",
        "\n",
        "def generator_loss(generated):\n",
        "  return mse_loss(generated, tf.ones_like(generated))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCwvpUiDPz9k",
        "colab_type": "text"
      },
      "source": [
        "## Cycle Consistency Loss\n",
        "\n",
        "1. Image X is passed via generator G that yields generated image $\\hat{Y}$.\n",
        "2. Generated image $\\hat Y$ is passed via generator F that yields cycled image $\\hat X$.\n",
        "3. Mean absolute error is calculated between X and $\\hat X$.\n",
        "\n",
        "$\\text{forward cycle consistency loss: } X->G(X)->F(G(X))\\sim \\hat X $\n",
        "\n",
        "$\\text{backward cycle consistency loss: } Y->F(Y)->G(F(Y))\\sim \\hat Y $\n",
        "\n",
        "![alt text](https://www.tensorflow.org/tutorials/generative/images/cycle_loss.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jgwZ9D3PuH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_cycle_loss(real_image, cycled_image):\n",
        "  return LAMBDA * mae_loss(real_image, cycled_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBabrZ00TcAg",
        "colab_type": "text"
      },
      "source": [
        "## Identity Loss\n",
        "\n",
        "The generator G is responsible for translating image X to image Y. Identity loss says that, if you feed image Y to generator G, it should yield real image Y or something close to Y.\n",
        "\n",
        "$\\text{Identity loss}=|G(Y)-Y|+|F(X)-X|$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcynhwVFTJSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identity_loss(real_image, same_image):\n",
        "  loss = mae_loss(real_image, same_image)\n",
        "\n",
        "  return LAMBDA * loss * 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "630PfgjpaCSd",
        "colab_type": "text"
      },
      "source": [
        "## Learning Rate Scheduler\n",
        "\n",
        "The learning rate is same for the first 100 epochs and linearly decay the rate to zero over the next 100 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOtaSAeBaBut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearDecay(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    # if `step` < `step_decay`: use fixed learning rate\n",
        "    # else: linearly decay the learning rate to zero\n",
        "    def __init__(self, initial_learning_rate, total_steps, step_decay):\n",
        "        super(LinearDecay, self).__init__()\n",
        "        self._initial_learning_rate = initial_learning_rate\n",
        "        self._steps = total_steps\n",
        "        self._step_decay = step_decay\n",
        "        self.current_learning_rate = tf.Variable(initial_value=initial_learning_rate, trainable=False, dtype=tf.float32)\n",
        "\n",
        "    def __call__(self, step):\n",
        "        self.current_learning_rate.assign(tf.cond(\n",
        "            step >= self._step_decay,\n",
        "            true_fn=lambda: self._initial_learning_rate * (1 - 1 / (self._steps - self._step_decay) * (step - self._step_decay)),\n",
        "            false_fn=lambda: self._initial_learning_rate\n",
        "        ))\n",
        "        return self.current_learning_rate\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\n",
        "            'initial_learning_rate': self._initial_learning_rate,\n",
        "            'total_steps': self._steps,\n",
        "            'step_decay': self._step_decay,\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzMoJeiVUDao",
        "colab_type": "text"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewAlWkxUUB8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_lr_scheduler = LinearDecay(LEARNING_RATE, EPOCHS * total_batches, DECAY_EPOCHS * total_batches)\n",
        "dis_lr_scheduler = LinearDecay(LEARNING_RATE, EPOCHS * total_batches, DECAY_EPOCHS * total_batches)\n",
        "\n",
        "# Initialize the optimizers for all the generators and the discriminators\n",
        "generator_G_optimizer = tf.keras.optimizers.Adam(learning_rate=gen_lr_scheduler, beta_1=BETA_1)\n",
        "generator_F_optimizer = tf.keras.optimizers.Adam(learning_rate=gen_lr_scheduler, beta_1=BETA_1)\n",
        "\n",
        "discriminator_X_optimizer = tf.keras.optimizers.Adam(learning_rate=dis_lr_scheduler, beta_1=BETA_1)\n",
        "discriminator_Y_optimizer = tf.keras.optimizers.Adam(learning_rate=dis_lr_scheduler, beta_1=BETA_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzi1-o9QUiRy",
        "colab_type": "text"
      },
      "source": [
        "# Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGZ3pbiLUg0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare a directory to store all the checkpoints\n",
        "checkpoint_dir = \"./checkpoints/train\"\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(generator_G=generator_G,\n",
        "                                generator_F=generator_F,\n",
        "                                discriminator_X=discriminator_X,\n",
        "                                discriminator_Y=discriminator_Y,\n",
        "                                generator_G_optimizer=generator_G_optimizer,\n",
        "                                generator_F_optimizer=generator_F_optimizer,\n",
        "                                discriminator_X_optimizer=discriminator_X_optimizer,\n",
        "                                discriminator_Y_optimizer=discriminator_Y_optimizer,\n",
        "                                epoch=tf.Variable(0))\n",
        "\n",
        "checkpoint_manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=2)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if checkpoint_manager.latest_checkpoint:\n",
        "  checkpoint.restore(checkpoint_manager.latest_checkpoint)\n",
        "  print(\"Restored from {}\".format(checkpoint_manager.latest_checkpoint))\n",
        "else:\n",
        "  print(\"Initializing from scratch.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udg01yHqU8Kn",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRGpy0rgaW5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "log_dir=\"logs/\"\n",
        "\n",
        "summary_writer = tf.summary.create_file_writer(\n",
        "                    log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgrq9yZxVEgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_images(model, test_input, name):\n",
        "  prediction = model(test_input)\n",
        "    \n",
        "  plt.figure(figsize=(12, 12))\n",
        "\n",
        "  display_list = [test_input[0], prediction[0]]\n",
        "  title = ['Input Image', 'Predicted Image']\n",
        "\n",
        "  for i in range(2):\n",
        "    plt.subplot(1, 2, i+1)\n",
        "    plt.title(title[i])\n",
        "    # getting the pixel values between [0, 1] to plot it.\n",
        "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "    plt.axis('off')\n",
        "\n",
        "  plt.savefig(fname=name, bbox_inches='tight')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8rjjnGiVQMh",
        "colab_type": "text"
      },
      "source": [
        "Training loop consists of four basic steps:\n",
        "\n",
        "1. Get the predictions\n",
        "2. Calculate the loss\n",
        "3. Calculate the gradient using backpropagation\n",
        "4. Apply the gradient to the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AvI5VpwVODC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(epoch, real_X, real_Y):\n",
        "  \n",
        "  # persistent is set to True because the tape is used more than once to calculate the gradients.\n",
        "  with tf.GradientTape(persistent=True) as tape:\n",
        "    # Generator G translates X -> Y\n",
        "    # Generator F translates Y -> X.\n",
        "    \n",
        "    fake_Y = generator_G(real_X, training=True)\n",
        "    cycled_X = generator_F(fake_Y, training=True)\n",
        "\n",
        "    fake_X = generator_F(real_Y, training=True)\n",
        "    cycled_Y = generator_G(fake_X, training=True)\n",
        "\n",
        "    # same_X and same_Y are used for identity loss.\n",
        "    same_X = generator_F(real_X, training=True)\n",
        "    same_Y = generator_G(real_Y, training=True)\n",
        "\n",
        "    disc_real_X = discriminator_X(real_X, training=True)\n",
        "    disc_real_Y = discriminator_Y(real_Y, training=True)\n",
        "\n",
        "    disc_fake_X = discriminator_X(fake_X, training=True)\n",
        "    disc_fake_Y = discriminator_Y(fake_Y, training=True)\n",
        "\n",
        "    # calculate the adversarial loss\n",
        "    gen_G_loss = generator_loss(disc_fake_Y)\n",
        "    gen_F_loss = generator_loss(disc_fake_X)\n",
        "    \n",
        "    # calculate the cycle consistent loss\n",
        "    total_cycle_loss = calc_cycle_loss(real_X, cycled_X) + calc_cycle_loss(real_Y, cycled_Y)\n",
        "    \n",
        "    # Total generator loss = adversarial loss + cycle loss\n",
        "    total_gen_G_loss = gen_G_loss + total_cycle_loss + identity_loss(real_Y, same_Y)\n",
        "    total_gen_F_loss = gen_F_loss + total_cycle_loss + identity_loss(real_X, same_X)\n",
        "\n",
        "    disc_X_loss = discriminator_loss(disc_real_X, disc_fake_X)\n",
        "    disc_Y_loss = discriminator_loss(disc_real_Y, disc_fake_Y)\n",
        "  \n",
        "  # Calculate the gradients for generator and discriminator\n",
        "  generator_G_gradients = tape.gradient(total_gen_G_loss, generator_G.trainable_variables)\n",
        "  generator_F_gradients = tape.gradient(total_gen_F_loss, generator_F.trainable_variables)\n",
        "  \n",
        "  discriminator_X_gradients = tape.gradient(disc_X_loss, discriminator_X.trainable_variables)\n",
        "  discriminator_Y_gradients = tape.gradient(disc_Y_loss, discriminator_Y.trainable_variables)\n",
        "  \n",
        "  # Apply the gradients to the optimizer\n",
        "  generator_G_optimizer.apply_gradients(zip(generator_G_gradients, generator_G.trainable_variables))\n",
        "  generator_F_optimizer.apply_gradients(zip(generator_F_gradients, generator_F.trainable_variables))\n",
        "  \n",
        "  discriminator_X_optimizer.apply_gradients(zip(discriminator_X_gradients, discriminator_X.trainable_variables))\n",
        "  discriminator_Y_optimizer.apply_gradients(zip(discriminator_Y_gradients, discriminator_Y.trainable_variables))\n",
        "\n",
        "  with summary_writer.as_default():\n",
        "    tf.summary.scalar('total_cycle_loss', total_cycle_loss, step=epoch)\n",
        "    tf.summary.scalar('total_gen_G_loss', total_gen_G_loss, step=epoch)\n",
        "    tf.summary.scalar('total_gen_F_loss', total_gen_F_loss, step=epoch)\n",
        "    tf.summary.scalar('gen_G_loss', gen_G_loss, step=epoch)\n",
        "    tf.summary.scalar('gen_F_loss', gen_F_loss, step=epoch)\n",
        "    tf.summary.scalar('disc_X_loss', disc_X_loss, step=epoch)\n",
        "    tf.summary.scalar('disc_Y_loss', disc_Y_loss, step=epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5RNDpW1X2uz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epochs, dataset):\n",
        "  for epoch in range(int(checkpoint.epoch), epochs):\n",
        "    start = time.time()\n",
        "    print('Epoch {} starts. Learning rate: {}, {}'.format(epoch, gen_lr_scheduler.current_learning_rate.value().numpy(),\n",
        "                                                                dis_lr_scheduler.current_learning_rate.value().numpy()))\n",
        "\n",
        "    for n, (image_x, image_y) in dataset.enumerate():\n",
        "      train_step(epoch, image_x, image_y)\n",
        "      if n % 10 == 0:\n",
        "        print ('.', end='')\n",
        "      \n",
        "    clear_output(wait=True)\n",
        "\n",
        "    # Using a consistent image (paintings) so that the progress of the model is clearly visible.\n",
        "    generate_images(generator_G, imgX, name=\"train_images/G_gen/to_landscape\" + str(epoch+1) + \".png\")\n",
        "    generate_images(generator_F, imgY, name=\"train_images/F_gen/to_painting\" + str(epoch+1) + \".png\")\n",
        "\n",
        "    # Save checkpoint\n",
        "    checkpoint.epoch.assign_add(1)\n",
        "\n",
        "    checkpoint_save_path = checkpoint_manager.save()\n",
        "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, checkpoint_save_path))\n",
        "\n",
        "    print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1, time.time()-start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0283BJAcZnzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {log_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM4bGVFwZpHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit(EPOCHS, train_dataset)\n",
        "print('Finished training.')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
